{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3,2 从MySql数据库读取数据\n",
    "import pymysql\n",
    "connection = pymysql.connect(host='172.17.6.26',\n",
    "                            port=3306,\n",
    "                            user='raa_user',\n",
    "                            password='bigdata123',\n",
    "                            charset='utf8mb4',\n",
    "                            db='risk_assessment_analysis',\n",
    "                            cursorclass=pymysql.cursors.DictCursor) \n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        sql = \"SELECT * FROM all_data\"\n",
    "        cursor.execute(sql)\n",
    "        all_data = cursor.fetchall()\n",
    "finally:\n",
    "    connection.close()\n",
    "# 查看数据前两个元素\n",
    "print(all_data[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 格式转换\n",
    "import pandas as pd\n",
    "\n",
    "#将列表转换为DataFrame\n",
    "data = pd.DataFrame(all_data)\n",
    "\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 查看数据前五行\n",
    "import pandas as pd\n",
    "\n",
    "# 使用head()函数查看数据前五行\n",
    "data_5 = data.head(5)\n",
    "\n",
    "print(data_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.4 查看数据的基本统计信息\n",
    "import pandas as pd\n",
    "\n",
    "# 使用describe()函数查看数据整体的基本统计信息\n",
    "data_des = data.describe(include = 'all') # 无include = all,只返回数值型数据\n",
    "\n",
    "\n",
    "print(data_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.5 是否违约特征分析\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "# 绘制柱状图，查看违约关系的取值分布情况\n",
    "data['Default'].value_counts(dropna = False).plot(kind = 'bar',rot = 40)\n",
    "\n",
    "# 在柱形上方显示计数\n",
    "counts = data['Default'].value_counts(dropna=False).values\n",
    "for index, item in zip([0,1,2], counts): \n",
    "    plt.text(index, item, item, ha=\"center\", va= \"bottom\", fontsize=12) \n",
    "\n",
    "# 设置柱形名称\n",
    "plt.xticks([0,1,2],['未违约','违约','NaN'])\n",
    "\n",
    "# 设置x、y轴标签\n",
    "plt.xlabel('是否违约')\n",
    "plt.ylabel('客户数量')\n",
    "\n",
    "# 设置标题以及字体大小\n",
    "plt.title('违约与未违约数量分布图',size = 13)\n",
    "\n",
    "# 设置中文显示\n",
    "plt.rcParams['font.sans-serif']=['SimHei'] \n",
    "plt.rcParams['font.family']=['sans-serif']\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.6 可视化城市级别与是否违约间的关系\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig,[ax1,ax2] = plt.subplots(1,2,figsize=(16,6))\n",
    "\n",
    "# 对CityId列的类别设定顺序\n",
    "data['CityId'] = data['CityId'].astype('category')\n",
    "data['CityId'] = data['CityId'].cat.set_categories(['一线城市', '二线城市', '其它'],ordered=True)\n",
    "\n",
    "# 绘制柱状图，查看不同城市级别在不同是否违约的取值分布情况\n",
    "sns.countplot(x = 'CityId',hue = 'Default',data = data,ax = ax1)\n",
    "\n",
    "# 将具体的计数值显示在柱形上方\n",
    "counts=data['Default'].groupby(data['CityId']).value_counts().values\n",
    "count1 = counts[[0, 2, 4]]\n",
    "count2 = counts[[1, 3, 5]]\n",
    "for index, item1, item2 in zip([0,1,2], count1, count2): \n",
    "    ax1.text(index-0.2, item1 + 0.05, '%.0f' % item1, ha=\"center\", va= \"bottom\",fontsize=12)\n",
    "    ax1.text(index+0.2, item2 + 0.05, '%.0f' % item2, ha=\"center\", va= \"bottom\",fontsize=12)\n",
    "    \n",
    "\n",
    "# 绘制柱状图查看违约率分布\n",
    "cityid_rate = data.groupby('CityId')['Default'].sum() / data.groupby('CityId')['Default'].count()\n",
    "sns.barplot(x = [0,1,2],y = cityid_rate.values,ax = ax2)\n",
    "\n",
    "# 将具体的计数值显示在柱形上方\n",
    "for index, item in zip([0,1,2], cityid_rate): \n",
    "     ax2.text(index, item, '%.3f' % item, ha=\"center\", va= \"bottom\",fontsize=12)\n",
    "        \n",
    "#设置柱形名称\n",
    "ax1.set_xticklabels(['一线城市','二线城市','其它'])\n",
    "ax2.set_xticklabels(['一线城市','二线城市','其它'])\n",
    "\n",
    "# 设置图例名称\n",
    "ax1.legend(labels = ['未违约','违约'])\n",
    "\n",
    "# 设置标题以及字体大小\n",
    "ax1.set_title('不同城市级别下不同违约情况数量分布柱状图',size = 13)\n",
    "ax2.set_title('不同城市级别违约率分布柱状图',size = 13)\n",
    "\n",
    "# 设置x,y轴标签\n",
    "ax1.set_xlabel('CityId')\n",
    "ax1.set_ylabel('客户人数')\n",
    "ax2.set_xlabel('CityId')\n",
    "ax2.set_ylabel('违约率')\n",
    "\n",
    "#显示汉语标注\n",
    "plt.rcParams['font.sans-serif']=['SimHei'] \n",
    "plt.rcParams['font.family']=['sans-serif']\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.7 可视化文化程度与是否违约间的关系\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig,[ax1,ax2] = plt.subplots(1,2,figsize=(16,6))\n",
    "\n",
    "# 对education列的类别设定顺序\n",
    "data['education'] = data['education'].astype('category')\n",
    "data['education'] = data['education'].cat.set_categories(['小学', '初中', '高中', '本科以上'],ordered=True)\n",
    "\n",
    "# 绘制柱状图，查看不同文化程度(education)在不同是否违约(Default)的取值分布情况\n",
    "sns.countplot(x = 'education',hue = 'Default',data = data,ax = ax1)\n",
    "\n",
    "# 将具体的计数值显示在柱形上方\n",
    "counts=data['Default'].groupby(data['education']).value_counts().values\n",
    "count1 = counts[[0, 2, 4,6]]\n",
    "count2 = counts[[1, 3, 5,7]]\n",
    "for index, item1, item2 in zip([0,1,2,3], count1, count2): \n",
    "    ax1.text(index-0.2, item1 + 0.05, '%.0f' % item1, ha=\"center\", va= \"bottom\",fontsize=12)\n",
    "    ax1.text(index+0.2, item2 + 0.05, '%.0f' % item2, ha=\"center\", va= \"bottom\",fontsize=12)\n",
    "\n",
    "\n",
    "# 绘制柱状图查看违约率分布\n",
    "education_rate = data.groupby('education')['Default'].sum() / data.groupby('education')['Default'].count()\n",
    "sns.barplot(x=[0,1,2,3],y=education_rate.values,ax=ax2)\n",
    "\n",
    "# 将具体的计数值显示在柱形上方\n",
    "for index, item in zip([0,1,2,3], education_rate): \n",
    "     ax2.text(index, item, '%.2f' % item, ha=\"center\", va= \"bottom\",fontsize=12)\n",
    "        \n",
    "# 设置柱形名称\n",
    "ax1.set_xticklabels(['小学','初中','高中','本科以上'])\n",
    "ax2.set_xticklabels(['小学','初中','高中','本科以上'])\n",
    "\n",
    "# 设置图例名称\n",
    "ax1.legend(labels = ['未违约','违约'])\n",
    "\n",
    "# 设置标题以及字体大小\n",
    "ax1.set_title('不同文化程度下不同违约情况数量分布柱状图',size = 13)\n",
    "ax2.set_title('不同文化程度下违约率分布柱状图',size = 13)\n",
    "\n",
    "# 设置x,y轴标签\n",
    "ax1.set_xlabel('education')\n",
    "ax1.set_ylabel('客户人数')\n",
    "ax2.set_xlabel('education')\n",
    "ax2.set_ylabel('违约率')\n",
    "\n",
    "#显示汉语标注\n",
    "plt.rcParams['font.sans-serif']=['SimHei'] \n",
    "plt.rcParams['font.family']=['sans-serif']\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.8 可视化三要素验证与是否违约间的关系\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig,[ax1,ax2] = plt.subplots(1,2,figsize=(16,6))\n",
    "\n",
    "# 对threeVerify列的类别设定顺序\n",
    "data['threeVerify'] = data['threeVerify'].astype('category')\n",
    "data['threeVerify'] = data['threeVerify'].cat.set_categories(['一致','不一致'],ordered=True)\n",
    "\n",
    "# 绘制柱状图，查看不同三要素验证情况(threeVerify)在不同是否违约(Default)的取值分布情况\n",
    "sns.countplot(x = 'threeVerify',hue = 'Default',data = data,ax = ax1)\n",
    "\n",
    "# 将具体的计数值显示在柱形上方\n",
    "counts=data['Default'].groupby(data['threeVerify']).value_counts().values\n",
    "count1 = counts[[0, 2]]\n",
    "count2 = counts[[1, 3]]\n",
    "for index, item1, item2 in zip([0,1,2,3], count1, count2): \n",
    "    ax1.text(index-0.2, item1 + 0.05, '%.0f' % item1, ha=\"center\", va= \"bottom\",fontsize=12)\n",
    "    ax1.text(index+0.2, item2 + 0.05, '%.0f' % item2, ha=\"center\", va= \"bottom\",fontsize=12)\n",
    "\n",
    "\n",
    "# 绘制柱状图查看违约率分布\n",
    "threeVerify_rate = data.groupby('threeVerify')['Default'].sum() / data.groupby('threeVerify')['Default'].count()\n",
    "sns.barplot(x=[0,1],y=threeVerify_rate.values,ax=ax2)\n",
    "\n",
    "# 将具体的计数值显示在柱形上方\n",
    "for index, item in zip([0,1], threeVerify_rate): \n",
    "     ax2.text(index, item, '%.2f' % item, ha=\"center\", va= \"bottom\",fontsize=12)\n",
    "        \n",
    "# 设置柱形名称\n",
    "ax1.set_xticklabels(['一致','不一致'])\n",
    "ax2.set_xticklabels(['一致','不一致'])\n",
    "\n",
    "# 设置图例名称\n",
    "ax1.legend(labels = ['未违约','违约'])\n",
    "\n",
    "# 设置标题以及字体大小\n",
    "ax1.set_title('不同三要素验证下不同违约情况数量分布柱状图',size = 13)\n",
    "ax2.set_title('不同三要素验证下违约率分布柱状图',size = 13)\n",
    "\n",
    "# 设置x,y轴标签\n",
    "ax1.set_xlabel('threeVerify')\n",
    "ax1.set_ylabel('客户人数')\n",
    "ax2.set_xlabel('threeVerify')\n",
    "ax2.set_ylabel('违约率')\n",
    "\n",
    "#显示汉语标注\n",
    "plt.rcParams['font.sans-serif']=['SimHei'] \n",
    "plt.rcParams['font.family']=['sans-serif']\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.9 可视化婚姻状况与是否违约的关系\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig,[ax1,ax2] = plt.subplots(1,2,figsize=(16,6))\n",
    "\n",
    "# 对maritalStatus列的类别设定顺序\n",
    "data['maritalStatus'] = data['maritalStatus'].astype('category')\n",
    "data['maritalStatus'] = data['maritalStatus'].cat.set_categories(['未婚','已婚'],ordered=True)\n",
    "\n",
    "# 绘制柱状图，查看不同婚姻状况在不同违约情况的取值分布\n",
    "sns.countplot('maritalStatus',hue = 'Default',data = data,ax = ax1)\n",
    "\n",
    "# 将具体的计数值显示在柱形上方\n",
    "counts=data['Default'].groupby(data['maritalStatus']).value_counts().values\n",
    "count1 = counts[[0, 2]]\n",
    "count2 = counts[[1, 3]]\n",
    "for index, item1, item2 in zip([0,1,2,3], count1, count2): \n",
    "    ax1.text(index-0.2, item1 + 0.05, '%.0f' % item1, ha=\"center\", va= \"bottom\",fontsize=12)\n",
    "    ax1.text(index+0.2, item2 + 0.05, '%.0f' % item2, ha=\"center\", va= \"bottom\",fontsize=12)\n",
    "\n",
    "\n",
    "# 绘制柱状图查看违约率分布\n",
    "maritalStatus_rate = data.groupby('maritalStatus')['Default'].sum() / data.groupby('maritalStatus')['Default'].count()\n",
    "sns.barplot(x = [0,1],y = maritalStatus_rate.values,ax = ax2)\n",
    "\n",
    "# 将具体的计数值显示在柱形上方\n",
    "for index, item in zip([0,1], maritalStatus_rate): \n",
    "     ax2.text(index, item, '%.2f' % item, ha=\"center\", va= \"bottom\",fontsize=12)\n",
    "        \n",
    "# 设置柱形名称\n",
    "ax1.set_xticklabels(['未婚','已婚'])\n",
    "ax2.set_xticklabels(['未婚','已婚'])\n",
    "\n",
    "# 设置图例名称\n",
    "ax1.legend(labels = ['未违约','违约'])\n",
    "\n",
    "# 设置标题以及字体大小\n",
    "ax1.set_title('不同婚姻状况下不同违约情况数量分布柱状图',size = 13)\n",
    "ax2.set_title('不同婚姻状况下违约率分布柱状图',size = 13)\n",
    "# 设置x,y轴标签\n",
    "ax1.set_xlabel('maritalStatus')\n",
    "ax1.set_ylabel('客户人数')\n",
    "ax2.set_xlabel('maritalStatus')\n",
    "ax2.set_ylabel('违约率')\n",
    "\n",
    "#显示汉语标注\n",
    "plt.rcParams['font.sans-serif']=['SimHei'] \n",
    "plt.rcParams['font.family']=['sans-serif']\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.10 可视化在网时长与是否违约的关系\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig,[ax1,ax2] = plt.subplots(1,2,figsize=(16,6))\n",
    "\n",
    "# 对netLength列的类别设定顺序\n",
    "data['netLength'] = data['netLength'].astype('category')\n",
    "data['netLength'] = data['netLength'].cat.set_categories(['0-6个月','6-12个月','12-24个月','24个月以上','无效'],ordered=True)\n",
    "\n",
    "# 绘制柱状图，查看不同在网时长在不同违约情况的取值分布\n",
    "sns.countplot(x = 'netLength',hue = 'Default',data = data,ax = ax1)\n",
    "\n",
    "# 将具体的计数值显示在柱形上方\n",
    "counts=data['Default'].groupby(data['netLength']).value_counts().values\n",
    "count1 = counts[[0,2,4,6,8]]\n",
    "count2 = counts[[1,3,5,7,9]]\n",
    "\n",
    "# 将具体的计数值显示在柱形上方\n",
    "for index, item1, item2 in zip([0,1,2,3,4], count1, count2): \n",
    "    ax1.text(index-0.2, item1 + 0.05, '%.0f' % item1, ha=\"center\", va= \"bottom\",fontsize=12)\n",
    "    ax1.text(index+0.2, item2 + 0.05, '%.0f' % item2, ha=\"center\", va= \"bottom\",fontsize=12)\n",
    "\n",
    "\n",
    "# 绘制柱状图查看违约率分布\n",
    "netLength_rate = data.groupby('netLength')['Default'].sum() / data.groupby('netLength')['Default'].count()\n",
    "sns.barplot(x=  [0,1,2,3,4],y = netLength_rate.values,ax = ax2)\n",
    "\n",
    "# 将具体的计数值显示在柱形上方\n",
    "for index, item in zip([0,1,2,3,4], netLength_rate): \n",
    "     ax2.text(index, item, '%.2f' % item, ha=\"center\", va= \"bottom\",fontsize=12)\n",
    "        \n",
    "# 设置柱形名称\n",
    "ax1.set_xticklabels(['0-6个月','6-12个月','12-24个月','24个月以上','无效'])\n",
    "ax2.set_xticklabels(['0-6个月','6-12个月','12-24个月','24个月以上','无效'])\n",
    "\n",
    "# 设置图例名称\n",
    "ax1.legend(labels = ['未违约','违约'])\n",
    "\n",
    "# 设置标题以及字体大小\n",
    "ax1.set_title('不同在网时长下不同违约情况数量分布柱状图',size = 13)\n",
    "ax2.set_title('不同在网时长下违约率分布柱状图',size = 13)\n",
    "\n",
    "# 设置x,y轴标签\n",
    "ax1.set_xlabel('netLength')\n",
    "ax1.set_ylabel('客户人数')\n",
    "ax2.set_xlabel('netLength')\n",
    "ax2.set_ylabel('违约率')\n",
    "\n",
    "#显示汉语标注\n",
    "plt.rcParams['font.sans-serif']=['SimHei'] \n",
    "plt.rcParams['font.family']=['sans-serif']\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.11 总消费金额的分布\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 建立画布ax1和ax2,及设置图像大小，设置subplots()函数中参数为(1,2)表示两画图呈一行两列\n",
    "fig, [ax1,ax2] = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# 在画布ax1中画出总消费金额的核密度图\n",
    "sns.kdeplot(data = data['transTotalAmt'],shade = True,ax = ax1)\n",
    "\n",
    "# 在画布ax2中画出总消费笔数和总消费金额的回归关系图\n",
    "sns.regplot(x = data['transTotalCnt'],y = data['transTotalAmt'],data = data,ax = ax2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.12 年龄和开卡时长分布\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 建立画布ax1和ax2,及设置图像大小，设置subplots()函数中参数为(1,2)表示一行两列\n",
    "fig,[ax1,ax2] = plt.subplots(1,2,figsize=(16,6))\n",
    "\n",
    "# 在画布ax1中绘制年龄的直方图，颜色为红色\n",
    "sns.distplot(data['age'],color = 'r',ax = ax1)\n",
    "\n",
    "# 在画布ax2中绘制开卡时长的直方图，颜色为默认值\n",
    "sns.distplot(data['card_age'],ax = ax2)\n",
    "\n",
    "# 在画布ax1、ax2中设置标题\n",
    "ax1.set_title('年龄分布')\n",
    "ax2.set_title('开卡时长分布')\n",
    "\n",
    "# 显示汉语标注\n",
    "plt.rcParams['font.sans-serif']=['SimHei'] \n",
    "plt.rcParams['font.family']=['sans-serif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.13 可视化总取现笔数和总取现金额的关系\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 建立画布ax1和ax2,及设置图像大小，设置subplots()函数中参数为(1,2)表示两画图呈一行两列\n",
    "fig, [ax1,ax2] = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# 在画布ax1中画出总取现金额的核密度图\n",
    "sns.kdeplot(data['cashTotalAmt'],shade = True,ax = ax1)\n",
    "\n",
    "# 在画布ax2中画出总取现笔数和总取现金额的回归关系图\n",
    "sns.regplot(x = data['cashTotalCnt'],y = data['cashTotalAmt'],ax = ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.14 可视化网上消费金额与笔数的关系\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 建立画布ax1和ax2,及设置图像大小，设置subplots()函数中参数为(1,2)表示两画图呈一行两列\n",
    "fig, [ax1,ax2] = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# 在画布ax1中画出网上消费金额的核密度估计曲线\n",
    "sns.kdeplot(data['onlineTransAmt'],shade = True,ax = ax1)\n",
    "\n",
    "# 在画布ax2中画出网上消费笔数和网上消费金额的回归关系图\n",
    "sns.regplot(x = data['onlineTransCnt'],y = data['onlineTransAmt'],ax = ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.15 查看存在缺失值的特征\n",
    "# 计算特征缺失值个数\n",
    "na_counts = data.isnull().sum()\n",
    "\n",
    "# 将na_counts取大于0的部分进行降序排序\n",
    "missing_value = na_counts[na_counts > 0].sort_values(ascending = False)\n",
    "\n",
    "# 查看存在缺失值的特征\n",
    "print(missing_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.16 离散型特征缺失值处理\n",
    "import pandas as pd\n",
    "\n",
    "# 缺失值处理\n",
    "data.dropna(subset=['Default'],inplace = True) #原地改变 False生成副本\n",
    "filling_columns = ['idVerify','maritalStatus','threeVerify','education','sex']\n",
    "for column in filling_columns:\n",
    "    data[column].fillna('未知',inplace = True)\n",
    "\n",
    "# 查看存在缺失值的特征\n",
    "na_counts = data.isnull().sum()\n",
    "missing_value = na_counts[na_counts > 0].sort_values(ascending = False)\n",
    "print(missing_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.17 离散型特征异常值处理\n",
    "import pandas as pd\n",
    "\n",
    "# 异常值处理\n",
    "data['isCrime'] = data['isCrime'].replace(2,0)\n",
    "\n",
    "# 查看处理后的数据情况\n",
    "print(data['isCrime'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.18  查看连续型特征的数值\n",
    "# 所有连续型特征列名已保存在continuous_columns中\n",
    "continuous_columns = ['age','cashTotalAmt','cashTotalCnt','monthCardLargeAmt','onlineTransAmt','onlineTransCnt','publicPayAmt','publicPayCnt','transTotalAmt','transTotalCnt','transCnt_non_null_months','transAmt_mean','transAmt_non_null_months','cashCnt_mean','cashCnt_non_null_months','cashAmt_mean','cashAmt_non_null_months','card_age']\n",
    "# 查看数据各连续型特征的最小值\n",
    "data_con_min = data[continuous_columns].min()\n",
    "print(data_con_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.19 网上消费金额异常值检测\n",
    "# 从原始数据中筛选出网上消费金额小于0时，网上消费金额和网上消费笔数这两列\n",
    "online_trans = data[data['onlineTransAmt'] < 0][['onlineTransAmt','onlineTransCnt']]\n",
    "print(online_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.20  网上消费金额异常值处理\n",
    "# 将网上消费笔数为0时的网上消费金额皆修改为0\n",
    "data.loc[data['onlineTransCnt'] == 0,'onlineTransAmt'] = 0\n",
    "# 查看修正后网上消费笔数为0时，网上消费金额与网上消费笔数\n",
    "online_after = data[data[\"onlineTransCnt\"]  == 0 ][[\"onlineTransAmt\",\"onlineTransCnt\"]] \n",
    "print(online_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.21 网上消费金额盒图绘制\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "fig,ax = plt.subplots(figsize=(8,6))\n",
    "# 绘制盒图查看网上消费金额数据分布\n",
    "sns.boxplot(data['onlineTransAmt'],orient = 'v')\n",
    "plt.title('onlineTransAmt distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.22 网上消费金额异常值处理\n",
    "# 筛选出网上消费金额在2千万以下的数据样本,更新data\n",
    "data = data[data['onlineTransAmt']<=2.0e+07]\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.23 公共事业缴费金额异常值检测\n",
    "# 从原始数据中筛选出公共事业缴费金额小于0时，公共事业缴费笔数和公共事业缴费金额这两列\n",
    "public_pay = data[data['publicPayAmt']<0][['publicPayCnt','publicPayAmt']]\n",
    "print(public_pay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.24 公共事业缴费金额异常值处理\n",
    "# 将公共事业缴费笔数为0时的公共事业缴费金额皆修改为0（直接在原始数据上进行修改）\n",
    "data.loc[data['publicPayCnt'] == 0,'publicPayAmt'] = 0\n",
    "\n",
    "# 查看修正后的，公共事业缴费笔数为0时的公共事业缴费金额与公共事业缴费笔数\n",
    "public_after = data[data[\"publicPayCnt\"]  ==  0][[\"publicPayAmt\",\"publicPayCnt\"]]\n",
    "print(public_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.25 公共事业缴费金额盒图绘制\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "fig,ax = plt.subplots(figsize=(8,6))\n",
    "# 绘制盒图查看公共事业缴费金额数据分布。\n",
    "sns.boxplot(data['publicPayAmt'],orient = 'v')\n",
    "plt.title('publicPayAmt distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.26 公共事业缴费金额异常值处理\n",
    "# 筛选出公共事业缴费金额小于-400万的样本数据\n",
    "public_pay = data[data['publicPayAmt'] < -4e+06]\n",
    "print(public_pay[['publicPayCnt','publicPayAmt']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.27 总消费金额异常值检测\n",
    "# 从原始数据中筛选出总消费笔数等于0时，总消费笔数，总消费金额这两列\n",
    "transTotal = data[data['transTotalCnt'] == 0][['transTotalCnt','transTotalAmt']]\n",
    "print(transTotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.28 总消费金额盒图绘制\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "fig,ax = plt.subplots(figsize=(8,6))\n",
    "# 绘制盒图，查看总消费金额数据分布。\n",
    "sns.boxplot(data['transTotalAmt'],orient = 'v')\n",
    "plt.title('transTotalAmt distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.29 总消费金额异常值处理\n",
    "# 筛选出总消费金额大于1000万的样本数据\n",
    "transTotal = data[data['transTotalAmt'] > 1.0e+07]\n",
    "print(transTotal[['transTotalAmt','transTotalCnt','onlineTransAmt','onlineTransCnt','monthCardLargeAmt']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.30 总取现金额异常值检测\n",
    "# 筛选出总取现笔数为0时，总取现笔数，总取现金额这两列\n",
    "cashTotal = data[data['cashTotalCnt'] == 0][['cashTotalCnt','cashTotalAmt']]\n",
    "print(cashTotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.31 总取现金额盒图绘制\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "fig,ax = plt.subplots(figsize=(8,6))\n",
    "# 绘制盒图，查看总取现金额数据分布。\n",
    "sns.boxplot(data['cashTotalAmt'],orient = 'v')\n",
    "plt.title('cashTotalAmt distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.32 总取现金额异常值处理\n",
    "# 筛选出总取现金额大于50万的样本数据。\n",
    "cashTotal = data[data['cashTotalAmt']>5.0e+05]\n",
    "print(cashTotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.33 月最大消费金额盒图绘制\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "fig,ax = plt.subplots(figsize=(8,6))\n",
    "# 绘制盒图，查看月最大消费金额数据分布\n",
    "sns.boxplot(data['monthCardLargeAmt'],orient = 'v')\n",
    "plt.title('monthCardLargeAmt distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.34 月最大消费异常值处理\n",
    "# 筛选出月最大消费金额大于200万的数据\n",
    "monthCard = data[data['monthCardLargeAmt']>2.0e+06]\n",
    "print(monthCard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.35 总消费笔数盒图绘制\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "fig,ax = plt.subplots(figsize=(8,6))\n",
    "# 绘制盒图，查看总消费笔数数据分布\n",
    "sns.boxplot(data['transTotalCnt'],orient = 'v')\n",
    "plt.title('transTotalCnt distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.36 总消费笔数异常值处理\n",
    "# 从data中筛选总消费笔数小于6000的值，赋值给data\n",
    "data = data[data['transTotalCnt']<6.0e+03]\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.37 数字编码\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data[\"maritalStatus\"] = data[\"maritalStatus\"].map({\"未知\":0,\"未婚\":1,\"已婚\":2})\n",
    "data['education']= data['education'].map({'未知':0,'小学':1,'初中':2,'高中':3,'本科以上':4})\n",
    "data['idVerify']= data['idVerify'].map({'未知':0,'一致':1,'不一致':2})\n",
    "data['threeVerify']= data['threeVerify'].map({'未知':0,'一致':1,'不一致':2})\n",
    "data[\"netLength\"] = data[\"netLength\"].map({'无效':0,'0-6个月':1,'6-12个月':2,'12-24个月':3,'24个月以上':4})\n",
    "data[\"sex\"] = data[\"sex\"].map({'未知':0,'男':1,'女':2})\n",
    "data[\"CityId\"] = data[\"CityId\"].map({'一线城市':1,'二线城市':2,'其它':3})\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.38 One-Hot编码\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.get_dummies(data = data,columns = ['maritalStatus','education','idVerify','threeVerify','Han','netLength','sex','CityId'])\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第五章"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 年消费总额指标计算\n",
    "# 计算客户年消费总额。\n",
    "trans_total =data['transCnt_mean'] * data['transAmt_mean']\n",
    "\n",
    "# 将计算结果保留到小数点后六位。\n",
    "trans_total =round(trans_total,6)\n",
    "\n",
    "# 将结果加在data数据集中的最后一列，并将此列命名为trans_total。\n",
    "data['trans_total'] = trans_total\n",
    "\n",
    "print(data['trans_total'].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.3 年取现总额指标计算\n",
    "# 计算客户年取现总额。\n",
    "total_withdraw = data['cashCnt_mean'] * data['cashAmt_mean']\n",
    "\n",
    "# 将计算结果保留到小数点后六位。\n",
    "total_withdraw = round(total_withdraw,6)\n",
    "\n",
    "# 将结果加在data数据集的最后一列，并将此列命名为total_withdraw。\n",
    "data['total_withdraw'] =total_withdraw\n",
    "\n",
    "print(data['total_withdraw'].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.4 平均每笔取现金额指标计算\n",
    "import numpy as np\n",
    "\n",
    "# 计算客户的平均每笔取现金额。\n",
    "avg_per_withdraw = data['cashTotalAmt']/data['cashTotalCnt']\n",
    "\n",
    "# 将所有的inf和NaN变为0。\n",
    "avg_per_withdraw = avg_per_withdraw.replace({np.nan:0,np.inf:0})\n",
    "\n",
    "# 将计算结果保留到小数点后六位。\n",
    "avg_per_withdraw =round(avg_per_withdraw,6)\n",
    "\n",
    "# 将结果加在data数据集的最后一列，并将此列命名为avg_per_withdraw。\n",
    "data['avg_per_withdraw'] =avg_per_withdraw\n",
    "\n",
    "print(data['avg_per_withdraw'].head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.5 网上平均每笔消费额指标计算\n",
    "import numpy as np\n",
    "\n",
    "# 请计算客户的网上平均每笔消费额。\n",
    "avg_per_online_spend =data['onlineTransAmt']/data['onlineTransCnt']\n",
    "\n",
    "# 将所有的inf和NaN变为0。\n",
    "avg_per_online_spend = avg_per_online_spend.replace({np.nan:0,np.inf:0})\n",
    "\n",
    "# 将计算结果保留到小数点后六位。\n",
    "avg_per_online_spend =round(avg_per_online_spend,6)\n",
    "\n",
    "# 将结果加在data数据集的最后一列，并将此列命名为avg_per_online_spend。\n",
    "data['avg_per_online_spend'] =avg_per_online_spend \n",
    "\n",
    "print(data['avg_per_online_spend'].head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.6 公共事业平均每笔缴费额指标计算\n",
    "import numpy as np\n",
    "\n",
    "# 请计算客户的公共事业平均每笔缴费额。\n",
    "avg_per_public_spend =data['publicPayAmt']/data['publicPayCnt']\n",
    "\n",
    "# 将所有的inf和NaN变为0。\n",
    "avg_per_public_spend = avg_per_public_spend.replace({np.nan:0,np.inf:0})\n",
    "\n",
    "# 将计算结果保留到小数点后六位。\n",
    "avg_per_public_spend =round(avg_per_public_spend,6)\n",
    "\n",
    "# 将结果加在data数据集的最后一列，并将此列命名为avg_per_public_spend。\n",
    "data['avg_per_public_spend'] =avg_per_public_spend\n",
    "\n",
    "print(data['avg_per_public_spend'].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.7 不良记录指标计算\n",
    "#请计算客户的不良记录分数。\n",
    "bad_record =data['inCourt']+data['isDue']+data['isCrime']+data['isBlackList']\n",
    "\n",
    "#将计算结果加在data数据集的最后一列，并将此列命名为bad_record。\n",
    "data['bad_record'] = bad_record\n",
    "\n",
    "print(data['bad_record'].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第六章"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.3 训练集与测试集划分\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 筛选data中的Default列的值，赋予变量y\n",
    "y = data['Default'].values\n",
    "\n",
    "# 筛选除去Default列的其他列的值，赋予变量x\n",
    "x = data.drop(['Default'], axis=1).values\n",
    "\n",
    "# 使用train_test_split方法，将x,y划分训练集和测试集\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state = 33,stratify = y)\n",
    "\n",
    "# 查看划分后的x_train与x_test的长度\n",
    "len_x_train = len(x_train)\n",
    "len_x_test = len(x_test)\n",
    "print('x_train length: %d, x_test length: %d'%(len_x_train,len_x_test))\n",
    "\n",
    "# 查看分层采样后的训练集中违约客户人数的占比\n",
    "train_ratio = y_train.sum()/len(y_train)\n",
    "print(train_ratio)\n",
    "\n",
    "# 查看分层采样后的测试集中违约客户人数的占比\n",
    "test_ratio = y_test.sum()/len(y_test)\n",
    "print(test_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.4 使用逻辑回归建立风险评估模型\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 调用模型，新建模型对象\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# 带入训练集x_train, y_train进行训练\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "# 对训练好的lr模型调用predict方法,带入测试集x_test进行预测\n",
    "y_predict = lr.predict(x_test)\n",
    "\n",
    "# 查看模型预测结果\n",
    "print(y_predict[:10])\n",
    "print(len(y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.5 逻辑回归风控模型效果评估\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y_predict_proba = lr.predict_proba(x_test)\n",
    "\n",
    "# 查看概率估计前十行\n",
    "print(y_predict_proba[:10])\n",
    "\n",
    "# 取目标分数为正类(1)的概率估计\n",
    "y_predict = y_predict_proba[:,1]\n",
    "\n",
    "# 利用roc_auc_score查看模型效果\n",
    "test_auc = roc_auc_score(y_test,y_predict)\n",
    "\n",
    "print('逻辑回归模型 test_auc:',test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.6 逻辑回归参数调优\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 建立一个LogisticRegression对象，命名为lr\n",
    "lr = LogisticRegression(penalty='l1',C= 0.6,class_weight='balanced')\n",
    "\n",
    "# 对lr对象调用fit方法，带入训练集x_train, y_train进行训练\n",
    "lr.fit(x_train,y_train)\n",
    "\n",
    "# 对训练好的lr模型调用predict_proba方法\n",
    "y_predict = lr.predict_proba(x_test)[:,1]\n",
    "\n",
    "# 调用roc_auc_score方法\n",
    "test_auc = roc_auc_score(y_test,y_predict)\n",
    "\n",
    "print('逻辑回归模型test auc:')\n",
    "print(test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.7 使用标准化提升逻辑回归模型效果\n",
    "continuous_columns = ['age','cashTotalAmt','cashTotalCnt','monthCardLargeAmt','onlineTransAmt','onlineTransCnt','publicPayAmt','publicPayCnt','transTotalAmt','transTotalCnt','transCnt_non_null_months','transAmt_mean','transAmt_non_null_months','cashCnt_mean','cashCnt_non_null_months','cashAmt_mean','cashAmt_non_null_months','card_age', 'trans_total','total_withdraw', 'avg_per_withdraw','avg_per_online_spend', 'avg_per_public_spend', 'bad_record','transCnt_mean','noTransWeekPre']\n",
    "\n",
    "# 对data中所有连续型的列进行Z-score标准化\n",
    "\n",
    "data[continuous_columns] = data[continuous_columns].apply(lambda x:(x-x.mean())/x.std())\n",
    "\n",
    "# 查看标准化后的数据的均值和标准差，以cashAmt_mean为例\n",
    "print('cashAmt_mean标准化后的均值：',data['cashAmt_mean'].mean())\n",
    "print('cashAmt_mean标准化后的标准差：',data['cashAmt_mean'].std())\n",
    "\n",
    "# 查看标准化后对模型的效果提升\n",
    "y = data['Default'].values\n",
    "x = data.drop(['Default'], axis=1).values\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2,random_state = 33,stratify=y)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(penalty='l1',C=0.6,class_weight='balanced')\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "# 查看模型预测结果\n",
    "y_predict = lr.predict_proba(x_test)[:,1]\n",
    "auc_score =roc_auc_score(y_test,y_predict)\n",
    "print('score:',auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.8 使用离散化提升逻辑回归模型效果\n",
    "continuous_columns = ['age','cashTotalAmt','cashTotalCnt','monthCardLargeAmt','onlineTransAmt','onlineTransCnt','publicPayAmt','publicPayCnt','transTotalAmt','transTotalCnt','transCnt_non_null_months','transAmt_mean','transAmt_non_null_months','cashCnt_mean','cashCnt_non_null_months','cashAmt_mean','cashAmt_non_null_months','card_age', 'trans_total','total_withdraw', 'avg_per_withdraw','avg_per_online_spend', 'avg_per_public_spend', 'bad_record','transCnt_mean','noTransWeekPre']\n",
    "\n",
    "# 对data中数值连续型的列进行等频离散化，将每一列都离散为5个组。\n",
    "data[continuous_columns] = data[continuous_columns].apply(lambda x: pd.qcut(x,5,duplicates='drop'))\n",
    "\n",
    "# 查看离散化后的数据\n",
    "print(data.head())\n",
    "\n",
    "# 查看离散化后对模型的效果提升\n",
    "# 先对各离散组进行One-Hot处理\n",
    "data=pd.get_dummies(data)\n",
    "y = data['Default'].values\n",
    "x = data.drop(['Default'], axis=1).values\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2,random_state = 33,stratify=y)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "lr = LogisticRegression(penalty='l1',C=0.6,class_weight='balanced')\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "# 查看模型预测结果\n",
    "y_predict = lr.predict_proba(x_test)[:,1]\n",
    "score_auc = roc_auc_score(y_test,y_predict)\n",
    "print('score:',score_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.9 使用随机森林建立风险评估模型\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "rf_clf = RandomForestClassifier()\n",
    "rf_clf.fit(x_train,y_train)\n",
    "y_predict = rf_clf.predict_proba(x_test)[:,1]\n",
    "\n",
    "# 查看模型效果\n",
    "test_auc = roc_auc_score(y_test,y_predict)\n",
    "print (\"AUC Score (Test): %f\" % test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.10 随机森林决策树数目参数调优\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# 尝试设置参数n_estimators\n",
    "rf_clf1 =  RandomForestClassifier(n_estimators=100)\n",
    "rf_clf1.fit(x_train, y_train)\n",
    "y_predict1 = rf_clf1.predict_proba(x_test)[:,1]\n",
    "\n",
    "# 查看模型效果\n",
    "test_auc = roc_auc_score(y_test,y_predict1)\n",
    "print (\"AUC Score (Test): %f\" % test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.11 随机森林参数调优\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 定义存储AUC分数的数组\n",
    "scores_train=[]\n",
    "scores_test=[]\n",
    "# 定义存储n_estimators取值的数组\n",
    "estimators=[]\n",
    "\n",
    "# 设置n_estimators在100-210中每隔20取一个数值\n",
    "for i in range(100,210,20):\n",
    "        estimators.append(i)\n",
    "        rf = RandomForestClassifier(n_estimators=i, random_state=12)\n",
    "        rf.fit(x_train,y_train)\n",
    "        y_predict = rf.predict_proba(x_test)[:,1]\n",
    "        scores_test.append(roc_auc_score(y_test,y_predict))\n",
    "\n",
    "# 查看我们使用的n_estimators取值\n",
    "print(\"estimators =\", estimators)\n",
    "\n",
    "# 查看以上模型中在测试集最好的评分\n",
    "print(\"best_scores_test =\",max(scores_test))\n",
    "\n",
    "# 画出n_estimators与AUC的图形\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "# 设置x y坐标名称\n",
    "ax.set_xlabel('estimators')\n",
    "ax.set_ylabel('AUC分数')\n",
    "plt.plot(estimators, scores_test, label='测试集')\n",
    "\n",
    "#显示汉语标注\n",
    "plt.rcParams['font.sans-serif']=['SimHei'] \n",
    "plt.rcParams['font.family']=['sans-serif']\n",
    "\n",
    "# 设置图例\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.12 使用网络搜索进行随机森林参数调优\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# 设置需要调试的参数\n",
    "tuned_parameters = {'n_estimators':[180,190],'max_depth':[8,10]}\n",
    "\n",
    "# 调用网格搜索函数\n",
    "rf_clf = GridSearchCV(rf,tuned_parameters,cv=5,n_jobs=2,scoring='roc_auc')\n",
    "rf_clf.fit(x_train, y_train)\n",
    "\n",
    "y_predict = rf_clf.predict_proba(x_test)[:,1]\n",
    "test_auc = roc_auc_score(y_test,y_predict)\n",
    "print ('随机森林模型test AUC:')\n",
    "print (test_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第七章"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.2 利用AUC评估逻辑回归模型准确性\n",
    "#用metrics.roc_curve()求出 fpr, tpr, threshold\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test,y_predict_best)\n",
    "\n",
    "#用metrics.auc求出roc_auc的值\n",
    "roc_auc = metrics.auc(fpr,tpr)\n",
    "\n",
    "#将图片大小设为8:6\n",
    "fig,ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "#将plt.plot里的内容填写完整\n",
    "plt.plot(fpr, tpr, label = 'AUC = %0.2f' % roc_auc)\n",
    "\n",
    "#将图例显示在右下方\n",
    "plt.legend(loc = 'lower right') \n",
    "\n",
    "#画出一条红色对角虚线\n",
    "plt.plot([0, 1], [0, 1],'r--') \n",
    "\n",
    "#设置横纵坐标轴范围\n",
    "plt.xlim([-0.01, 1.01]) \n",
    "plt.ylim([-0.01, 1.01])\n",
    "\n",
    "#设置横纵名称以及图形名称\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.3 利用AUC评估随机森林模型准确性\n",
    "#用metrics.roc_curve()求出 fpr, tpr, threshold\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test,y_predict_best)\n",
    "\n",
    "#用metrics.auc求出roc_auc的值\n",
    "roc_auc = metrics.auc(fpr,tpr)\n",
    "\n",
    "#将图片大小设为8:6\n",
    "fig,ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "#将plt.plot里的内容填写完整\n",
    "plt.plot(fpr, tpr, label = 'AUC = %0.2f' % roc_auc)\n",
    "\n",
    "#将图例显示在右下方\n",
    "plt.legend(loc = 'lower right') \n",
    "\n",
    "#画出一条红色对角虚线\n",
    "plt.plot([0, 1], [0, 1],'r--') \n",
    "\n",
    "#设置横纵坐标轴范围\n",
    "plt.xlim([-0.01, 1.01]) \n",
    "plt.ylim([-0.01, 1.01])\n",
    "\n",
    "#设置横纵名称以及图形名称\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.4 利用KS值评估逻辑回归模型准确性\n",
    "#用metric.roc_curve()求出 fpr, tpr, threshold\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, y_predict_best)\n",
    "\n",
    "#求出KS值和相应的阈值\n",
    "ks = max(abs(tpr-fpr))\n",
    "thre = threshold[abs(tpr-fpr).argmax()]\n",
    "\n",
    "ks = round(ks*100, 2)\n",
    "thre = round(thre, 2)\n",
    "print('KS值：', ks,  '%', '阈值：', thre)\n",
    "\n",
    "#将图片大小设为8:6\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "#将plt.plot里的内容填写完整\n",
    "\n",
    "plt.plot(threshold[::-1], tpr[::-1], lw=1, alpha=1,label='真正率TPR')\n",
    "plt.plot(threshold[::-1], fpr[::-1], lw=1, alpha=1,label='假正率FPR')\n",
    "\n",
    "\n",
    "#画出KS值的直线\n",
    "ks_tpr = tpr[abs(tpr-fpr).argmax()]\n",
    "ks_fpr = fpr[abs(tpr-fpr).argmax()]\n",
    "x1 = [thre, thre]\n",
    "x2 = [ks_fpr, ks_tpr]\n",
    "plt.plot(x1, x2)\n",
    "\n",
    "#设置横纵名称以及图例\n",
    "plt.xlabel('阈值')\n",
    "plt.ylabel('真正率TPR/假正率FPR')\n",
    "plt.title('KS曲线', fontsize=15)\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.grid(axis='x')\n",
    "\n",
    "# 在图上标注ks值\n",
    "plt.annotate('KS值', xy=(0.18, 0.45), xytext=(0.25, 0.43),\n",
    "             fontsize=20,arrowprops=dict(facecolor='green', shrink=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.5\n",
    "#用metric.roc_curve()求出 fpr, tpr, threshold\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, y_predict_best)\n",
    "\n",
    "#求出KS值和相应的阈值\n",
    "ks =  max(abs(tpr-fpr))\n",
    "thre = threshold[abs(tpr-fpr).argmax()]\n",
    "\n",
    "ks = round(ks*100, 2)\n",
    "thre = round(thre, 2)\n",
    "print('KS值：', ks,  '%', '阈值：', thre)\n",
    "\n",
    "#将图片大小设为8:6\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "#将plt.plot里的内容填写完整\n",
    "\n",
    "plt.plot(threshold[::-1], tpr[::-1], lw=1, alpha=1,label='真正率TPR')\n",
    "plt.plot(threshold[::-1], fpr[::-1], lw=1, alpha=1,label='假正率FPR')\n",
    "\n",
    "\n",
    "#画出KS值的直线\n",
    "ks_tpr = tpr[abs(tpr-fpr).argmax()]\n",
    "ks_fpr = fpr[abs(tpr-fpr).argmax()]\n",
    "x1 = [thre, thre]\n",
    "x2 = [ks_fpr, ks_tpr]\n",
    "plt.plot(x1, x2)\n",
    "\n",
    "#设置横纵名称以及图例\n",
    "plt.xlabel('阈值')\n",
    "plt.ylabel('真正率TPR/假正率FPR')\n",
    "plt.title('KS曲线', fontsize=15)\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.grid(axis='x')\n",
    "\n",
    "# 在图上标注ks值\n",
    "plt.annotate('KS值', xy=(0.26, 0.45), xytext=(0.30, 0.43),\n",
    "             fontsize=20,arrowprops=dict(facecolor='green', shrink=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.6 利用PSI评估逻辑回归模型稳定性\n",
    "## 训练集预测概率\n",
    "y_train_probs = lr.predict_proba(x_train)[:,1]\n",
    "## 测试集预测概率\n",
    "y_test_probs = lr.predict_proba(x_test)[:,1]\n",
    "\n",
    "def psi(y_train_probs, y_test_probs):\n",
    "    ## 设定每组的分点\n",
    "    bins = np.arange(0, 1.1, 0.1)\n",
    "    \n",
    "    ## 将训练集预测概率分组\n",
    "    y_train_probs_cut = pd.cut(y_train_probs, bins=bins, labels=False)\n",
    "    ## 计算预期占比\n",
    "    expect_prop = (pd.Series(y_train_probs_cut).value_counts()/len(y_train_probs)).sort_index()\n",
    "    \n",
    "    ## 将测试集预测概率分组\n",
    "    y_test_probs_cut = pd.cut(y_test_probs, bins=bins, labels=False)\n",
    "    ## 计算实际占比\n",
    "    actual_prop = (pd.Series(y_test_probs_cut).value_counts()/len(y_test_probs)).sort_index()\n",
    "    \n",
    "    ## 计算PSI\n",
    "    psi = ((actual_prop - expect_prop) * np.log(actual_prop/expect_prop)).sum()\n",
    "    \n",
    "    return psi, expect_prop, actual_prop\n",
    "\n",
    "## 运行函数得到psi、预期占比和实际占比\n",
    "psi, expect_prop, actual_prop = psi(y_train_probs, y_test_probs)\n",
    "print('psi=',psi)\n",
    "\n",
    "## 创建(12, 8)的绘图框\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "\n",
    "## 设置中文字体\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei'] \n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "## 绘制条形图\n",
    "plt.bar(expect_prop.index + 0.2, expect_prop, width=0.4, label='预期占比')\n",
    "plt.bar(actual_prop.index - 0.2, actual_prop, width=0.4, label='实际占比')\n",
    "plt.legend()\n",
    "\n",
    "## 设置轴标签\n",
    "plt.xlabel('概率分组', fontsize=12)\n",
    "plt.ylabel('样本占比', fontsize=12)\n",
    "\n",
    "## 设置轴刻度\n",
    "plt.xticks([0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "           ['0-0.1', '0.1-0.2', '0.2-0.3', '0.3-0.4', '0.4-0.5', '0.5-0.6', '0.6-0.7', '0.7-0.8', '0.8-0.9', '0.9-1'])\n",
    "\n",
    "## 设置图标题\n",
    "plt.title('预期占比与实际占比对比条形图', fontsize=15)\n",
    "\n",
    "## 在图上添加文字\n",
    "for index, item1, item2 in zip(range(10), expect_prop.values, actual_prop.values): \n",
    "    plt.text(index+0.2, item1 + 0.01, '%.3f' % item1, ha=\"center\", va= \"bottom\",fontsize=10)\n",
    "    plt.text(index-0.2, item2 + 0.01, '%.3f' % item2, ha=\"center\", va= \"bottom\",fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.7  利用PSI评估随机森林模型稳定性\n",
    "## 训练集预测概率\n",
    "y_train_probs = rf.predict_proba(x_train)[:,1]\n",
    "## 测试集预测概率\n",
    "y_test_probs = rf.predict_proba(x_test)[:,1]\n",
    "\n",
    "def psi(y_train_probs, y_test_probs):\n",
    "    ## 设定每组的分点\n",
    "    bins = np.arange(0, 1.1, 0.1)\n",
    "    \n",
    "    ## 将训练集预测概率分组\n",
    "    y_train_probs_cut = pd.cut(y_train_probs, bins=bins, labels=False)\n",
    "    ## 计算预期占比\n",
    "    expect_prop = (pd.Series(y_train_probs_cut).value_counts()/len(y_train_probs)).sort_index()\n",
    "    \n",
    "    ## 将测试集预测概率分组\n",
    "    y_test_probs_cut = pd.cut(y_test_probs, bins=bins, labels=False)\n",
    "    ## 计算实际占比\n",
    "    actual_prop = (pd.Series(y_test_probs_cut).value_counts()/len(y_test_probs)).sort_index()\n",
    "    \n",
    "    ## 计算PSI\n",
    "    psi = ((actual_prop - expect_prop) * np.log(actual_prop/expect_prop)).sum()\n",
    "    \n",
    "    return psi, expect_prop, actual_prop\n",
    "\n",
    "## 运行函数得到psi、预期占比和实际占比\n",
    "psi, expect_prop, actual_prop = psi(y_train_probs, y_test_probs)\n",
    "print('psi=', round(psi, 3))\n",
    "\n",
    "## 创建(12, 8)的绘图框\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "\n",
    "## 设置中文字体\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei'] \n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "## 绘制条形图\n",
    "plt.bar(expect_prop.index + 0.2, expect_prop, width=0.4, label='预期占比')\n",
    "plt.bar(actual_prop.index - 0.2, actual_prop, width=0.4, label='实际占比')\n",
    "plt.legend()\n",
    "\n",
    "## 设置轴标签\n",
    "plt.xlabel('概率分组', fontsize=12)\n",
    "plt.ylabel('样本占比', fontsize=12)\n",
    "\n",
    "## 设置轴刻度\n",
    "plt.xticks([0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "           ['0-0.1', '0.1-0.2', '0.2-0.3', '0.3-0.4', '0.4-0.5', '0.5-0.6', '0.6-0.7', '0.7-0.8', '0.8-0.9', '0.9-1'])\n",
    "\n",
    "## 设置图标题\n",
    "plt.title('预期占比与实际占比对比条形图', fontsize=15)\n",
    "\n",
    "## 在图上添加文字\n",
    "for index, item1, item2 in zip(range(10), expect_prop.values, actual_prop.values): \n",
    "    plt.text(index+0.2, item1 + 0.01, '%.3f' % item1, ha=\"center\", va= \"bottom\",fontsize=10)\n",
    "    plt.text(index-0.2, item2 + 0.01, '%.3f' % item2, ha=\"center\", va= \"bottom\",fontsize=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.8 计算逻辑回归的指标重要性\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_clf = LogisticRegression(penalty='l1',C = 0.6, random_state=55)\n",
    "lr_clf.fit(x_train, y_train)\n",
    "\n",
    "# 查看逻辑回归各项指标系数\n",
    "coefficient = lr_clf.coef_\n",
    "\n",
    "# 取出指标系数，并对其求绝对值\n",
    "importance = abs(coefficient)\n",
    "\n",
    "# 通过图形的方式直观展现前八名的重要指标\n",
    "index=data.drop('Default', axis=1).columns\n",
    "feature_importance = pd.DataFrame(importance.T, index=index).sort_values(by=0, ascending=True)\n",
    "\n",
    "# # 查看指标重要度\n",
    "print(feature_importance)\n",
    "\n",
    "# 水平条形图绘制\n",
    "feature_importance.tail(8).plot(kind='barh', title='Feature Importances', figsize=(8, 6), legend=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.9 计算随机森林的指标重要性\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators = 150, criterion = 'entropy', max_depth = 5, min_samples_split = 2, random_state=12)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# 查看随机森林各项指标系数\n",
    "importance = rf.feature_importances_\n",
    "\n",
    "# 通过图形的方式直观展现前八名的重要指标\n",
    "index=data.drop('Default', axis=1).columns\n",
    "feature_importance = pd.DataFrame(importance.T, index=index).sort_values(by=0, ascending=True)\n",
    "\n",
    "# # 查看指标重要度\n",
    "print(feature_importance)\n",
    "\n",
    "# 水平条形图绘制\n",
    "feature_importance.tail(8).plot(kind='barh', title='Feature Importances', figsize=(8, 6), legend=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
