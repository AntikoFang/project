{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第二章"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 从MySql数据库中读取交易流水数据\n",
    "import pymysql\n",
    "\n",
    "# 建立连接对象\n",
    "connection = pymysql.connect(host = '172.17.6.26',\n",
    "                    port = 3306,\n",
    "                   user = 'raa_user',\n",
    "                   password = 'bigdata123',\n",
    "                    db = 'transactions',\n",
    "                    charset = 'utf8mb4')\n",
    "\n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        # 查询数据表行数\n",
    "        sql1 = \"SELECT count(*) FROM flow_data\"\n",
    "        # 选取表的前五行\n",
    "        sql2 = \"SELECT * FROM flow_data LIMIT 5\"\n",
    "\n",
    "        cursor.execute(sql1)\n",
    "        rows = cursor.fetchall() \n",
    "        cursor.execute(sql2)\n",
    "        head = cursor.fetchall() \n",
    "\n",
    "finally:\n",
    "    connection.close()\n",
    "\n",
    "# 查看数据的行列数\n",
    "print('数据行数为:',rows,'\\n前五行数据为:',head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 对客户数据进行格式转换\n",
    "import pandas as pd\n",
    "\n",
    "# 将data转换为DataFrame格式\n",
    "data = pd.DataFrame(list(data),columns=['user_id','payment','describe','unix_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第三章"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b30552b4f11a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# 查看数据形状\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"数据共有 %s 行，有 %s 列。\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# 3.2 数据统计分析\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 查看数据形状\n",
    "rows, cols = data.shape\n",
    "\n",
    "print(\"数据共有 %s 行，有 %s 列。\" % (rows, cols))\n",
    "\n",
    "# 查看数据的前五行\n",
    "head = data.head()\n",
    "\n",
    "print('\\n',head)\n",
    "\n",
    "# 查看数据的基本情况\n",
    "data.info(null_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 查看客户总数\n",
    "import pandas as pd\n",
    "\n",
    "# 计算客户个数\n",
    "user_num = len(set(data['user_id']))\n",
    "print(\"客户总数为:\",user_num)\n",
    "\n",
    "# 计算客户交易次数\n",
    "user_counts = data['user_id'].value_counts()\n",
    "print(\"每个客户的交易次数为:\\n\",user_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4 交易时间异常值检测\n",
    "import pandas as pd\n",
    "\n",
    "# 书写正则表达式\n",
    "pattern = '^\\d{10}$'\n",
    "\n",
    "# 筛选异常值\n",
    "outlier = data[~data['unix_time'].str.match(pattern)]  # 不是10位数字组成的\n",
    "\n",
    "# 统计不同类型的异常值及其数量\n",
    "outlier_counts = outlier['unix_time'].value_counts()\n",
    "\n",
    "print(outlier_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.5 交易时间异常值处理\n",
    "import pandas as pd\n",
    "\n",
    "# 去掉交易时间为0的行\n",
    "data = data.loc[data['unix_time'] != 0]\n",
    "\n",
    "# 将异常值填补为正常值\n",
    "data.loc[data['unix_time'] == '14 3264000','unix_time'] = 1473264000\n",
    "\n",
    "print(data.loc[data['unix_time'] == '14 3264000'])\n",
    "print(data.loc[data['unix_time'] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.6 交易金额异常值处理\n",
    "import pandas as pd\n",
    "\n",
    "# 查看交易金额为'\\N'的行数\n",
    "print(\"交易金额异常的记录共有%s行。\" % (len(data[data['payment'] == '\\\\N'])))\n",
    "\n",
    "# 去除交易金额为'\\N'的行\n",
    "data = data[data['payment'] != '\\\\N']\n",
    "\n",
    "print(data[data['payment'] == '\\\\N'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.7 交易附言缺失值处理\n",
    "import pandas as pd\n",
    "\n",
    "# 筛选describe中有无附言为空的行\n",
    "describe_null =  data[data['describe'].isnull()]\n",
    "\n",
    "print(\"交易附言为空的行共有%s条。\"%  len(describe_null))\n",
    "print(describe_null.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.8 时间格式和时区转换\n",
    "import pandas as pd\n",
    "\n",
    "# 时间格式转换\n",
    "data['pay_time'] = pd.to_datetime(data['unix_time'],unit = 's')\n",
    "\n",
    "# 时区转换\n",
    "data['pay_time'] = data['pay_time'] + pd.Timedelta(hours = 8)\n",
    "\n",
    "print(data.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.9 量纲转换\n",
    "import pandas as pd\n",
    "\n",
    "# 将payment列标准化\n",
    "data['payment'] = data['payment']/100\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.10重复数据处理\n",
    "import pandas as pd\n",
    "\n",
    "# 检测重复值\n",
    "duplicate_values = data[data.duplicated()]\n",
    "print(\"重复数据有%s行。\"% len(duplicate_values))\n",
    "\n",
    "# 去掉重复值\n",
    "data.drop_duplicates(inplace = True) # 在原数据上进行更改\n",
    "print(\"处理之后，交易记录变为%s行。\" % len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第四章"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 交易次数随时间的可视化分析\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "\n",
    "# 绘制折线图\n",
    "data['pay_time'].dt.date.value_counts().plot()\n",
    "\n",
    "# 设置图形标题\n",
    "plt.title('不同时间的交易次数分布')\n",
    "\n",
    "# 设置y轴标签\n",
    "plt.ylabel('交易次数')\n",
    "\n",
    "# 设置x轴标签\n",
    "plt.xlabel('时间')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 交易金额随时间的可视化分析\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "\n",
    "# 绘制折线图\n",
    "abs(data['payment']).groupby(data['pay_time'].dt.date).sum().plot()\n",
    "\n",
    "# 设置图形标题\n",
    "plt.title('不同时间的交易金额分布')\n",
    "\n",
    "# 设置y轴标签\n",
    "plt.ylabel('交易金额')\n",
    "\n",
    "# 设置x轴标签\n",
    "plt.xlabel('时间')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.4 交易有效时间段的限定\n",
    "import pandas as pd\n",
    "\n",
    "# 时间限定\n",
    "data = data[(data['pay_time'] <= pd.Timestamp(2018,1,1)) & (data['pay_time'] >= pd.Timestamp(2016,7,1))]\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.5 每天24小时交易次数的分布\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "\n",
    "# 绘制条形图\n",
    "data['pay_time'].dt.hour.value_counts().sort_index().plot.bar(color = 'orange',rot = 360)\n",
    "\n",
    "# 设置图形标题\n",
    "plt.title('每天24小时的交易次数分布')\n",
    "\n",
    "# 设置x轴标签\n",
    "plt.xlabel('小时')\n",
    "\n",
    "# 设置y轴标签\n",
    "plt.ylabel('交易次数')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.6 客户交易次数的可视化分布\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(16, 5))\n",
    "\n",
    "# 绘制核密度图\n",
    "sns.kdeplot(data['user_id'].value_counts(),shade = True,legend = False)\n",
    "\n",
    "# 设置x，y轴标签\n",
    "plt.xlabel('交易次数')\n",
    "plt.ylabel('频率')\n",
    "\n",
    "# 设置图的标题\n",
    "plt.title('客户交易次数')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.7 客户平均交易金额的可视化分析\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(16, 5))\n",
    "\n",
    "# 绘制核密度图\n",
    "sns.kdeplot(abs(data['payment']).groupby(data['user_id']).mean(),shade = True,legend = False)\n",
    "\n",
    "# 设置x，y轴标签\n",
    "plt.xlabel('平均交易金额')\n",
    "plt.ylabel('频率')\n",
    "\n",
    "# 设置图的标题\n",
    "plt.title('客户平均交易金额的分布')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.8 客户交易流入流出次数的可视化分析\n",
    "import seaborn as sns\n",
    "\n",
    "fig,[ax1,ax2] = plt.subplots(1,2,figsize=(16, 5))\n",
    "\n",
    "# 定义和选取金额流入流出的交易记录\n",
    "input_payment = data[data['payment'] < 0]\n",
    "output_payment = data[data['payment'] > 0]\n",
    "\n",
    "# 计算每个客户的流入流出次数\n",
    "input_payment_count = input_payment.groupby('user_id').size()\n",
    "output_payment_count = output_payment.groupby('user_id').size()\n",
    "\n",
    "# 绘制直方图\n",
    "sns.distplot(input_payment_count,ax=ax1)\n",
    "sns.distplot(output_payment_count,ax=ax2)\n",
    "\n",
    "# 设置标题\n",
    "ax1.set_title('客户交易的流入次数分布')\n",
    "ax2.set_title('客户交易的流出次数分布')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.9 客户交易流入流出金额的可视化分析\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 定义和选取金额流入流出的交易记录\n",
    "input_payment = data[data['payment'] < 0]\n",
    "output_payment = data[data['payment'] > 0]\n",
    "\n",
    "# 计算每个客户的流入流出金额\n",
    "input_payment_amount = input_payment.groupby('user_id')['payment'].mean()\n",
    "output_payment_amount = output_payment.groupby('user_id')['payment'].mean()\n",
    "\n",
    "fig,[ax1,ax2] = plt.subplots(1,2,figsize=(16, 5))\n",
    "\n",
    "# 绘制直方图\n",
    "sns.distplot(input_payment_amount,ax = ax1)\n",
    "sns.distplot(output_payment_amount,ax = ax2)\n",
    "\n",
    "# 设置标题\n",
    "ax1.set_title('客户交易的平均流入金额分布')\n",
    "ax2.set_title('客户交易的平均流出金额分布')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.10 交易附言文本预处理\n",
    "import pandas as pd\n",
    "import jieba\n",
    "\n",
    "# 数据采样\n",
    "data = data.sample(20000,random_state = 22)\n",
    "\n",
    "# 文本分词\n",
    "data['describe_cutted'] = data['describe'].apply(lambda x:\" \".join(jieba.cut(x)))\n",
    "\n",
    "# 过滤停用词  \n",
    "def del_stopwords(words):  \n",
    "    output = ''  \n",
    "    for word in words:  \n",
    "        if word not in stopwords:  \n",
    "            output += word\n",
    "    return output\n",
    "\n",
    "data['describe_cutted'] = data['describe_cutted'].apply(del_stopwords)\n",
    "\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.11 交易附言词云绘制\n",
    "from wordcloud import WordCloud         \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 数据采样\n",
    "data = data.sample(20000,random_state = 22)\n",
    "\n",
    "# 文本拼接\n",
    "describe_document = \" \".join(data['describe_cutted'])\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "# 创建词云对象\n",
    "wordcloud = WordCloud(background_color = 'white',\n",
    "                      font_path = \"FangSong.ttf\",\n",
    "                      mask = background_Image,\n",
    "                      collocations = False,\n",
    "                      scale = 2,\n",
    "                      random_state = 30)\n",
    "\n",
    "# 生成词云\n",
    "wordcloud.generate(describe_document)\n",
    "\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.12 交易附言关键词提取\n",
    "import jieba\n",
    "       \n",
    "# 提取关键词\n",
    "tags = jieba.analyse.extract_tags(describe_document,withWeight = True,topK = 50)\n",
    "\n",
    "# 输出关键词\n",
    "for tag in tags:\n",
    "    print(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第五章"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2 事实类标签的计算（交易次数和交易总额）\n",
    "import pandas as pd\n",
    "\n",
    "user_features = pd.DataFrame(index = data[\"user_id\"].unique())\n",
    "\n",
    "# 计算客户的交易次数\n",
    "user_features['total_transactions_cnt'] = data.groupby('user_id').size()\n",
    "\n",
    "# 计算客户的交易总金额\n",
    "user_features['total_transactions_amt'] = abs(data.payment).groupby(data['user_id']).sum()\n",
    "\n",
    "print(user_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.3 事实类标签的计算（转账次数和转账金额）\n",
    "import pandas as pd\n",
    "\n",
    "# 提取包含转账行为的记录\n",
    "transfer = data[data['describe'].str.contains('转账')] #附言中是否有转账这个词\n",
    "\n",
    "# 计算客户的转账次数\n",
    "user_features[\"transfer_cnt\"] = transfer.groupby('user_id').size()\n",
    "\n",
    "# 计算客户的转账总金额\n",
    "user_features[\"transfer_amt\"] = abs(transfer.payment).groupby(transfer['user_id']).sum()\n",
    "\n",
    "# 计算客户的转账平均金额\n",
    "user_features[\"transfer_mean\"] = abs(transfer.payment).groupby(transfer['user_id']).mean()\n",
    "\n",
    "print(user_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.4 事实类标签的计算（其他）\n",
    "import pandas as pd\n",
    "\n",
    "# 1.单次最大消费金额\n",
    "user_features[\"max_consume_amt\"] = consume.groupby(by='user_id').apply(lambda x: max(x['payment']))\n",
    "\n",
    "# 2.消费订单比例\n",
    "user_features[\"consume_order_ratio\"] = consume.groupby(by='user_id').size() / user_features['total_transactions_cnt']\n",
    "\n",
    "# 3.月均消费频度\n",
    "standard_day = pd.Timestamp(2018,1,1)\n",
    "consume['distance'] = (standard_day - consume['pay_time']) / pd.Timedelta(days=30)\n",
    "user_features['mon_consume_frq'] = consume.groupby(by='user_id').apply(lambda x: len(x) / x['distance'].max())\n",
    "\n",
    "# 4.最常用支付工具\n",
    "consume_info = data[data.payment > 0]   \n",
    "pay = consume_info[consume_info[\"describe\"].str.contains('转账|支付|还款|充值|交易')]  # 支付\n",
    "pay['paytool'] = ''\n",
    "for i in range(len(pay)):\n",
    "   if '支付宝' in pay.iloc[i,2]:\n",
    "    pay.iloc[i,-1] = 'Alipay'\n",
    "   elif '淘宝' in pay.iloc[i,2]:\n",
    "    pay.iloc[i,-1] = 'Alipay'\n",
    "   elif '余额宝' in pay.iloc[i,2]:\n",
    "    pay.iloc[i,-1] = 'Alipay'\n",
    "   elif '信用卡' in pay.iloc[i,2]:\n",
    "    pay.iloc[i,-1] = 'CreditcardPay'\n",
    "   elif '银联' in pay.iloc[i,2]:\n",
    "    pay.iloc[i,-1] = 'UnionPay'\n",
    "   else:\n",
    "    pay.iloc[i,-1] = 'OthersPay'\n",
    "user_features['consumption_channel'] = pay['paytool'].groupby('user_id').value_counts().max()\n",
    "\n",
    "\n",
    "# 5.网购订单次数\n",
    "user_features['online_cnt'] = online.groupby(by='user_id').size()\n",
    "\n",
    "# 6.网购订单总金额\n",
    "user_features['online_amt'] = online.groupby(by='user_id')['payment'].sum()\n",
    "\n",
    "# 7.网购订单平均金额\n",
    "user_features['online_avg_amt'] = online.groupby(by='user_id')['payment'].mean()\n",
    "\n",
    "# 8.月均网购频度\n",
    "user_features['mon_online_frq'] = online.groupby(by='user_id').apply(lambda x: len(x) / x['distance'].max())\n",
    "\n",
    "# 9.网购首单时间\n",
    "user_features['online_buy_first_date'] = online.groupby(by='user_id').apply(lambda x: pd.Timestamp(2018,1,1) - pd.Timedelta(days=x.max()))\n",
    "\n",
    "# 10.网购尾单时间\n",
    "user_features['online_buy_last_date'] = online.groupby(by='user_id').apply(lambda x: pd.Timestamp(2018,1,1) - pd.Timedelta(days=x.min()))\n",
    "\n",
    "# 提取餐饮消费的记录\n",
    "dining = consume[consume[\"describe\"].str.contains(\"餐饮|食\")]\n",
    "\n",
    "# 11.餐饮订单次数\n",
    "user_features['dining_cnt'] = dining.groupby(by='user_id').size()\n",
    "\n",
    "# 12.餐饮订单总金额\n",
    "user_features['dining_amt'] = dining.groupby(by='user_id')['payment'].sum()\n",
    "\n",
    "# 13.餐饮订单平均金额\n",
    "user_features['ding_avg_amt'] = dining.groupby(by='user_id')['payment'].mean()\n",
    "\n",
    "# 提取商旅消费的记录\n",
    "train_bus = consume[consume[\"describe\"].str.contains(\"车票|火车票|机票\")]\n",
    "travel_hotel = consume[consume[\"describe\"].str.contains(\"住宿|宾馆|酒店|携程|去哪\")]\n",
    "business_travel = pd.concat([train_bus,travel_hotel])\n",
    "\n",
    "# 14.商旅消费次数\n",
    "user_features[\"business_travel_cnt\"] = business_travel.groupby(\"user_id\").size()\n",
    "\n",
    "# 15.商旅消费总金额\n",
    "user_features[\"business_travel_amt\"] = business_travel.payment.groupby(business_travel[\"user_id\"]).sum()\n",
    "\n",
    "# 16.商旅消费平均金额\n",
    "user_features[\"business_travel_avg_amt\"] = business_travel.payment.groupby(business_travel[\"user_id\"]).mean()\n",
    "\n",
    "# 17.月均旅行频次\n",
    "user_features['mon_business_travel_frq'] = business_travel.groupby(by='user_id').apply(lambda x: len(x) / x['distance'].max())\n",
    "\n",
    "# 提取汽车消费记录\n",
    "car = consume[consume['describe'].str.contains('汽车')]\n",
    "\n",
    "# 18.汽车消费次数\n",
    "user_features['car_cnt'] = car.groupby(by='user_id').size()\n",
    "\n",
    "# 19.汽车消费总金额\n",
    "user_features['car_amt'] = car.groupby(by='user_id')['payment'].sum()\n",
    "\n",
    "# 20.有无代发\n",
    "user_features['payroll'] = consume.groupby(by='user_id').apply(lambda x: '代发' in ' '.join(x['describe']))\n",
    "\n",
    "# 提取退货记录\n",
    "return_goods = consume_less[consume_less['describe'].str.contains('退货')]\n",
    "\n",
    "# 21.退货订单数\n",
    "user_features['return_cnt'] = return_goods.groupby(by='user_id').size()\n",
    "\n",
    "# 提取公共事业缴费的记录\n",
    "public = consume_info[consume_info[\"describe\"].str.contains('水费|电费|燃气费')]\n",
    "\n",
    "# 22.公共事业缴费总额\n",
    "user_features[\"public_pay_amt\"] = public.groupby(\"user_id\")['payment'].sum()\n",
    "\n",
    "# 提取网络媒体类消费记录\n",
    "net_media = consume[consume['describe'].str.contains('充值|会员')]\n",
    "\n",
    "# 23.网络媒体类消费次数\n",
    "user_features['internet_media_cnt'] = net_media.groupby(by='user_id').size()\n",
    "\n",
    "# 24.网络媒体类消费总金额\n",
    "user_features['internet_media_amt'] = net_media.groupby(by='user_id')['payment'].sum()\n",
    "\n",
    "# 提取话费消费记录\n",
    "tele_dill = consume[consume['describe'].str.contains('话费')]\n",
    "\n",
    "# 25.话费通讯类消费次数\n",
    "user_features['phone_fee_cnt'] = tele_dill.groupby(by='user_id').size()\n",
    "\n",
    "# 26.话费通讯类消费总金额\n",
    "user_features['phone_fee_amt'] = tele_dill.groupby(by='user_id')['payment'].sum()\n",
    "\n",
    "# 27.有无分期\n",
    "user_features['is_installment'] = consume.groupby(by='user_id').apply(lambda x: '分期' in ' '.join(x['describe']))\n",
    "\n",
    "# 提取预借记录\n",
    "pre_lend = consume_less[consume_less['describe'].str.contains('预借')]\n",
    "\n",
    "# 28.预借现金次数\n",
    "user_features['cash_advance_cnt'] = pre_lend.groupby(by='user_id').size()\n",
    "\n",
    "# 29.预借现金总金额\n",
    "user_features['cash_advance_amt'] = pre_lend.groupby(by='user_id')['payment'].sum()\n",
    "\n",
    "# 30.计算客户的交易次数(上面有)\n",
    "user_features['total_transactions_cnt'] = data.groupby(by='user_id').apply(lambda x: len(x))\n",
    "\n",
    "# 31.计算客户的交易总金额(上面有)\n",
    "user_features['total_transactions_amt'] = data.groupby(by='user_id').apply(lambda x: sum(abs(x['payment'])))\n",
    "\n",
    "# 提取提现记录\n",
    "withdraw = consume[consume['describe'].str.contains('提现')]\n",
    "\n",
    "# 32.提现次数\n",
    "user_features['withdraw_cnt'] = withdraw.groupby(by='user_id').size()\n",
    "\n",
    "# 33.提现总金额\n",
    "user_features['withdraw_amt'] = withdraw.groupby(by='user_id')['payment'].sum()\n",
    "\n",
    "# 34.ATM存款总金额\n",
    "user_features['total_deposit'] = consume[consume['describe'].str.contains('ATM存款')].groupby(by='user_id')['payment'].sum()\n",
    "\n",
    "# 35.ATM取款总金额\n",
    "user_features['total_withdraw'] = consume[consume['describe'].str.contains('ATM取款')].groupby(by='user_id')['payment'].sum()\n",
    "\n",
    "# 提取转账记录\n",
    "transfer = data[data['describe'].str.contains('转账')]\n",
    "\n",
    "# 36.计算客户的转账次数\n",
    "user_features[\"transfer_cnt\"] = transfer.groupby(by='user_id').apply(lambda x: len(x))\n",
    "\n",
    "# 37.计算客户的转账总金额\n",
    "user_features[\"transfer_amt\"] = transfer.groupby(by='user_id').apply(lambda x: sum(abs(x['payment'])))\n",
    "\n",
    "# 38.计算客户的转账平均金额\n",
    "user_features[\"transfer_mean\"] = transfer.groupby(by='user_id').apply(lambda x: abs(x['payment']).mean())\n",
    "\n",
    "# 提取信用卡还款记录\n",
    "credit = consume_info[consume_info['describe'].str.contains('信用卡还款')]\n",
    "\n",
    "# 39.信用卡还款次数\n",
    "user_features['credit_card_repay_cnt'] = credit.groupby(by='user_id').size()\n",
    "\n",
    "# 40.信用卡还款总金额\n",
    "user_features['credit_card_repay_amt'] = credit.groupby(by='user_id')['payment'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.5 规则类标签的计算（有无高端消费）\n",
    "import pandas as pd\n",
    "\n",
    "# 计算阈值\n",
    "threshold = user_features['max_consume_amt'].quantile(0.75)\n",
    "\n",
    "# 判定有无高端消费\n",
    "user_features[\"high_consumption\"] = user_features['max_consume_amt'].apply(lambda x: 1 if x > threshold else 0)\n",
    "\n",
    "print(user_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.6 规则类标签的计算（是否休眠客户）\n",
    "import pandas as pd\n",
    "\n",
    "# 计算阈值  下四分位数\n",
    "threshold = user_features['total_transactions_cnt'].quantile(0.25)\n",
    "\n",
    "# 判定是否休眠\n",
    "user_features['sleep_customers'] = user_features['total_transactions_cnt'].apply(lambda x:1 if x < threshold else 0)\n",
    "\n",
    "print(user_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.8 规则类标签的计算（计算时间差）\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 选取观察点\n",
    "standard_day = pd.Timestamp(2018,1,1)\n",
    "\n",
    "# 计算天数\n",
    "consume['distance'] = standard_day - consume['pay_time']\n",
    "consume['distance'] = consume['distance'] / pd.Timedelta(days = 1)\n",
    "\n",
    "print(consume.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.9 规则类标签的计算（近度，频度，值度）\n",
    "import pandas as pd\n",
    "\n",
    "# 计算rfm\n",
    "user_features[['recency','frequency','monetary']] = consume.groupby('user_id').agg({'distance':'min','user_id':'size','payment':'sum'})\n",
    "\n",
    "print(user_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.10 规则类标签的计算（RFM总得分）\n",
    "import pandas as pd\n",
    "\n",
    "# 等频离散化\n",
    "user_features['R_score'] = pd.qcut(user_features['recency'],4,labels = [4,3,2,1])\n",
    "user_features['F_score'] = pd.qcut(user_features['frequency'],4,labels = [1,2,3,4])\n",
    "user_features['M_score'] = pd.qcut(user_features['monetary'],4,labels = [1,2,3,4])\n",
    "\n",
    "# 填充缺失值\n",
    "user_features[['R_score','F_score','M_score']] = user_features[['R_score','F_score','M_score']].fillna(1)\n",
    "\n",
    "# 计算总得分\n",
    "user_features['Total_Score'] = user_features.R_score.astype('int') + user_features.F_score.astype('int') + user_features.M_score.astype('int')\n",
    "\n",
    "print(user_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.11 RFM可视化分析\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig,[ax1,ax2,ax3] = plt.subplots(1,3,figsize=(16,4))\n",
    "\n",
    "# 绘制条形图\n",
    "user_features.groupby('Total_Score')['recency'].mean().plot(kind='bar', colormap='Blues_r',ax=ax1, rot=360)\n",
    "user_features.groupby('Total_Score')['frequency'].mean().plot(kind='bar', colormap='Blues_r',ax=ax2, rot=360)\n",
    "user_features.groupby('Total_Score')['monetary'].mean().plot(kind='bar', colormap='Blues_r',ax=ax3, rot=360)\n",
    "\n",
    "# 设置y轴标签\n",
    "ax1.set_ylabel('recency')\n",
    "ax2.set_ylabel('frequency')\n",
    "ax3.set_ylabel('monetary')\n",
    "\n",
    "# 自动调整子图间距\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.12 客户价值等级数据的读取\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "\n",
    "# 从数据库读入客户价值等级数据\n",
    "connection = pymysql.connect(host='172.17.6.26', \n",
    "                             port = 3306, \n",
    "                             user = 'raa_user', \n",
    "                             password = 'bigdata123', \n",
    "                             db = 'transactions',\n",
    "                             charset = 'utf8mb4')\n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        sql = \"SELECT * FROM user_potential\"\n",
    "        cursor.execute(sql)\n",
    "        level = cursor.fetchall() \n",
    "finally:\n",
    "    connection.close()\n",
    "\n",
    "level=pd.DataFrame(list(level),columns = ['user_id','user_potential'])\n",
    "\n",
    "print(level.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.13 One-Hot编码\n",
    "import pandas as pd\n",
    "\n",
    "# 对消费渠道进行One-hot编码\n",
    "user_features_predict = pd.get_dummies(data = user_features_predict,columns = ['consumption_channel'],prefix = '',prefix_sep='')\n",
    "\n",
    "print(user_features_predict.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.14 日期等距离离散化\n",
    "import pandas as pd\n",
    "\n",
    "# 对网购首单时间进行离散化\n",
    "user_features_predict['online_buy_first_date'] = pd.cut(user_features_predict['online_buy_first_date'],bins = 6,labels = False,duplicates = 'drop')\n",
    "\n",
    "# 对网购最后一次时间进行离散化\n",
    "user_features_predict['online_buy_last_date'] = pd.cut(user_features_predict['online_buy_last_date'],bins = 6,labels = False,duplicates = 'drop')\n",
    "\n",
    "print(user_features_predict[['online_buy_first_date','online_buy_last_date']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.15 连续型数值等频离散化\n",
    "import pandas as pd\n",
    "\n",
    "# 所有数值为连续型的列\n",
    "continuous_col = ['max_consume_amt', 'consume_order_ratio', 'mon_consume_frq', 'online_cnt', 'online_amt', 'online_avg_amt', 'mon_online_frq','dining_cnt','dining_amt', 'dining_avg_amt', 'business_travel_cnt','business_travel_amt', 'business_travel_avg_amt', 'mon_business_travel_frq', 'car_cnt', 'car_amt', 'phone_fee_cnt', 'phone_fee_amt', 'credit_card_repay_cnt', 'credit_card_repay_amt','cash_advance_cnt', 'cash_advance_amt', 'payroll','total_transactions_amt', 'total_transactions_cnt', 'withdraw_cnt','withdraw_amt', 'total_deposit', 'total_withdraw', 'transfer_cnt','transfer_amt', 'transfer_mean', 'internet_media_cnt', 'internet_media_amt', 'public_pay_amt', 'return_cnt',  'recency', 'frequency', 'monetary']\n",
    "\n",
    "# 对所有连续型数值的列进行等频离散化\n",
    "user_features_predict[continuous_col] = user_features_predict[continuous_col].apply(lambda x:pd.qcut(x,6,duplicates = 'drop',labels=False))\n",
    "    \n",
    "print(user_features_predict.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.16 训练测试集的划分\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 提取有价值等级客户的数据\n",
    "customers = user_features_predict[user_features_predict[\"user_potential\"].notnull()]\n",
    "\n",
    "# 提取X，y\n",
    "y = customers.user_potential\n",
    "X = customers.drop(['user_potential'],axis=1)\n",
    "\n",
    "# 划分训练集、测试集\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y,test_size = 0.2,random_state = 33)\n",
    "\n",
    "print(x_train.shape,x_test.shape,y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.17 构建客户价值等级预测模型\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 设置分类器\n",
    "clf = LogisticRegression()\n",
    "\n",
    "# 训练\n",
    "clf.fit(x_train,y_train)\n",
    "\n",
    "# 预测\n",
    "y_predict = clf.predict(x_test)\n",
    "\n",
    "# 计算准确率\n",
    "score = clf.score(x_test,y_test)\n",
    "\n",
    "# 以百分数形式输出并保留两位小数\n",
    "print('%.2f%%'%(score*100))\n",
    "\n",
    "# 输出分类报告\n",
    "report = classification_report(y_test,y_predict)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.18 预测客户价值阶段\n",
    "import pandas as pd\n",
    "\n",
    "# 选取价值等级未知的客户数据\n",
    "null_customers = user_features_predict[user_features_predict['user_potential'].isnull()]\n",
    "\n",
    "# 对价值等级未知的客户进行预测\n",
    "null_customers[\"user_potential\"] =  clf.predict(null_customers.drop(['user_potential'],axis = 1))\n",
    "\n",
    "# 将数据合并在原始表中\n",
    "user_features['user_potential'] = pd.concat([customers['user_potential'],null_customers['user_potential']],axis=0)\n",
    "\n",
    "print(user_features[\"user_potential\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.19 客户价值等级分布\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 计算不同客户价值等级的客户数量\n",
    "lmt_num = user_features[\"user_potential\"].value_counts()\n",
    "\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "\n",
    "# 绘制柱状图，查看客户价值等级取值分布情况\n",
    "lmt_num.plot(kind = \"bar\",rot=360,width = 0.15)\n",
    "\n",
    "# 设置柱形名称\n",
    "plt.xticks([0,1],['低价值','高价值'])\n",
    "\n",
    "# 设置x、y轴标签\n",
    "plt.ylabel(\"客户数量\")\n",
    "plt.xlabel(\"客户价值等级\")\n",
    "\n",
    "# 设置标题\n",
    "plt.title(\"客户价值等级分布图\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.20 客户标签间的相关性\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 取所有标签的后15列\n",
    "last_features = user_features.iloc[:,-15:]\n",
    "\n",
    "# 计算各标签间的皮尔森相关系数\n",
    "corr = abs(last_features.corr())\n",
    "\n",
    "fig = plt.figure(figsize = (10,10))\n",
    "\n",
    "# 设置颜色风格\n",
    "cmap = sns.cubehelix_palette(8, start = 2, rot = 0, dark = 0, light =0.95)\n",
    "\n",
    "# 绘制热力图\n",
    "sns.heatmap(corr,annot = True,linewidths = 0.05,cmap = cmap)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.21 客户价值等级与是否拥有高端消费的可视化分析\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 计算交叉表\n",
    "counts = pd.crosstab(user_features[\"high_consumption\"],user_features[\"user_potential\"])\n",
    "\n",
    "# 重命名索引和列名\n",
    "counts.index = [\"无高端消费\",\"有高端消费\"]\n",
    "counts.columns= [\"低价值客户\",\"高价值客户\"]\n",
    "\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "\n",
    "# 绘制柱状图\n",
    "counts.plot(kind =\"bar\",rot = 360,width = 0.3)\n",
    "\n",
    "# 设置x、y轴标签\n",
    "plt.ylabel(\"人数\")\n",
    "plt.xlabel(\"有无高端消费\")\n",
    "\n",
    "# 设置标题\n",
    "plt.title(\"客户价值等级与是否拥有高端消费之间的关系\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.22 月均消费频度的可视化分析\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 设置画布大小\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "\n",
    "# 绘制月均消费频度的取值分布直方图\n",
    "sns.distplot(user_features['mon_consume_frq'],color='pink')\n",
    "\n",
    "# 设置标题\n",
    "plt.title(\"月均消费频度取值分布\")\n",
    "\n",
    "# 设置x轴标签\n",
    "plt.xlabel(\"月均消费频度\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.23 客户价值等级与月均消费频度的可视化分析\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 将月均消费频度取值划分到不同区间\n",
    "frq_range = pd.cut(user_features['mon_consume_frq'],[0,15,30,45,60,75],right = False)\n",
    "\n",
    "# 计算交叉表\n",
    "counts = pd.crosstab(frq_range,user_features['user_potential'])\n",
    "\n",
    "# 重命名列名\n",
    "counts.columns = ['低价值客户','高价值用户']\n",
    "\n",
    "fig = plt.figure(figsize = (8,6))\n",
    "\n",
    "# 绘制柱状图\n",
    "counts.plot(kind = 'bar',rot = 360,width = 0.7)\n",
    "\n",
    "# 设置x、y轴标签\n",
    "plt.xlabel('月均消费频度')\n",
    "plt.ylabel('人数')\n",
    "\n",
    "# 设置标题\n",
    "plt.title('客户价值等级与月均消费频度的关系')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.25 合并交易附言\n",
    "import pandas as pd\n",
    "\n",
    "## 分组合并交易附言\n",
    "describe_sum = data.groupby('user_id')['describe_cutted'].sum()\n",
    "\n",
    "print(describe_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.26 CountVectorizer词频矩阵计算\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# 建立CountVectorizer模型\n",
    "count_vec = CountVectorizer(stop_words = stop_words_list,min_df = 5,max_df = 5000,max_features = 100)\n",
    "\n",
    "# 计算词频矩阵\n",
    "sparse_result_count = count_vec.fit_transform(describe_sum)\n",
    "\n",
    "# 输出稀疏矩阵\n",
    "print(sparse_result_count)\n",
    "\n",
    "# 输出关键词\n",
    "print('\\nvocabulary list:\\n\\n',count_vec.get_feature_names())\n",
    "\n",
    "# 输出关键词编号\n",
    "print('\\nvocabulary dic:\\n\\n',count_vec.vocabulary_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.27 TfidfVectorizer词频矩阵计算\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 建立TfidfVectorizer模型\n",
    "tfidf_vec = TfidfVectorizer(stop_words = stop_words_list,min_df = 5,max_df = 5000,max_features = 100)\n",
    "\n",
    "# 计算tfidf矩阵\n",
    "sparse_result_tfidf = tfidf_vec.fit_transform(describe_sum)\n",
    "\n",
    "# 输出稀疏矩阵\n",
    "print(sparse_result_tfidf)\n",
    "\n",
    "# 输出关键词\n",
    "print('\\nvocabulary list:\\n\\n',tfidf_vec.get_feature_names())\n",
    "\n",
    "# 输出关键词编号\n",
    "print( '\\nvocabulary dic :\\n\\n',tfidf_vec.vocabulary_)\n",
    "\n",
    "# 与user_features表进行合并\n",
    "user_features = pd.concat([user_features,pd.DataFrame(sparse_result_tfidf.toarray(),index = user_features.index)],axis=1)\n",
    "\n",
    "# 输出合并后user_features表的行列数\n",
    "print('\\n合并后客户标签表的行列数为:\\n\\n',user_features.shape)\n",
    "\n",
    "# 重命名列名\n",
    "columns_mapping = {value:key for key, value in tfidf_vec.vocabulary_.items()}\n",
    "user_features.rename(columns = columns_mapping,inplace=True)\n",
    "\n",
    "# 输出重命名后user_features表的列名\n",
    "print('\\n合并后客户标签表的列名为:\\n\\n',user_features.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.28 描绘用户画像\n",
    "from wordcloud import WordCloud         \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 选取文本\n",
    "describe_selected = describe_sum[user_features['total_transactions_cnt'].idxmax()]\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "# 创建词云对象\n",
    "wordcloud = WordCloud(background_color=\"white\", \n",
    "                      mask = background_male,\n",
    "                      stopwords = stop_words,\n",
    "                      font_path = \"SimHei.ttf\",\n",
    "                      collocations = False,\n",
    "                      scale = 4,\n",
    "                      random_state = 30)\n",
    "\n",
    "# 生成词云\n",
    "wordcloud.generate(describe_selected)\n",
    "\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.29 客户文本标签的分析\n",
    "import pandas as pd\n",
    "\n",
    "# 选取存放文本标签词频的行和列\n",
    "tfidf_features = user_features.loc[10014615][-100:]\n",
    "\n",
    "# 选取出现最多的前20个交易附言关键词\n",
    "top_describe = tfidf_features.sort_values(ascending = False)[:20]\n",
    "\n",
    "print(top_describe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.30 客户数值标签的分析\n",
    "import pandas as pd\n",
    "\n",
    "# 查看该客户的数值标签\n",
    "number_feature = user_features.loc[10014615][0:50]\n",
    "\n",
    "print(number_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.31 描绘用户画像\n",
    "from wordcloud import WordCloud         \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 选取文本\n",
    "describe_selected = describe_sum[12521063]\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "# 创建词云对象\n",
    "wordcloud = WordCloud(background_color=\"white\", \n",
    "                      mask = background_female,\n",
    "                      stopwords = stop_words,\n",
    "                      font_path = \"SimHei.ttf\",\n",
    "                      collocations = False,\n",
    "                      scale = 4,\n",
    "                      random_state = 30)\n",
    "\n",
    "# 生成词云\n",
    "wordcloud.generate(describe_selected)\n",
    "\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.32 客户文本标签的分析\n",
    "import pandas as pd\n",
    "\n",
    "# 选取存放文本标签词频的行和列\n",
    "tfidf_features = user_features.loc[12521063][-100:]\n",
    "\n",
    "# 选取出现最多的前20个交易附言关键词\n",
    "top_describe = tfidf_features.sort_values(ascending = False)[:20]\n",
    "\n",
    "print(top_describe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.33 客户数值标签的分析\n",
    "import pandas as pd\n",
    "\n",
    "# 查看该客户的数字特征\n",
    "number_feature = user_features.loc[12521063][0:50]\n",
    "\n",
    "print(number_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第六章"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.3 时间差的计算\n",
    "import pandas as pd\n",
    "\n",
    "# 选取观察点\n",
    "standard_day=pd.Timestamp(2018,1,1)\n",
    "\n",
    "# 计算月数\n",
    "consume['distance']= (standard_day-consume['pay_time'])/pd.Timedelta(days=30)\n",
    "\n",
    "print(consume.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.4\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "eta = 0.5\n",
    "text_list = '停彩|大乐透|双色球|福利彩票|彩票|竞彩|追号'\n",
    "\n",
    "# 筛选彩票类的消费记录\n",
    "lottery_ticket = consume[consume['describe'].str.contains(text_list)]\n",
    "\n",
    "# 基于时间的商品兴趣度\n",
    "user_features['time_penalty'] = lottery_ticket.groupby('user_id')['distance'].agg(lambda x:sum(np.exp(-eta*x)))\n",
    "\n",
    "print(user_features['time_penalty'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.5\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "text_list = '停彩|大乐透|双色球|福利彩票|彩票|竞彩|追号'\n",
    "\n",
    "# 筛选彩票类的消费记录\n",
    "lottery_ticket = consume[consume['describe'].str.contains(text_list)]\n",
    "\n",
    "# 计算消费金额\n",
    "user_features['payment_sum'] = lottery_ticket.groupby('user_id')['payment'].sum()\n",
    "\n",
    "print(user_features['payment_sum'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.6 基于tf-idf的商品兴趣度计算\n",
    "import pandas as pd\n",
    "\n",
    "# 选取字段\n",
    "lottery_tfidf = user_features[['停彩','大乐透','双色球','福利彩票','彩票','竞彩','追号']]\n",
    "\n",
    "# tfidf求和\n",
    "user_features['tfidf_sum'] = lottery_tfidf.sum(axis = 1)  #按行相加\n",
    "\n",
    "print(user_features['tfidf_sum'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.7 数据归一化\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# sigmoid归一化\n",
    "user_features['time_penalty'] = user_features[['time_penalty']].apply(lambda x:1/(1+np.exp(-x)))\n",
    "\n",
    "# min-max归一化\n",
    "user_features['payment_sum'] = user_features[['payment_sum']].apply(lambda x : (x - x.min())/(x.max()-x.min()))\n",
    "user_features['tfidf_sum'] = user_features[['tfidf_sum']].apply(lambda x : (x - x.min())/(x.max()-x.min()))\n",
    "\n",
    "print(user_features[['time_penalty','payment_sum','tfidf_sum']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.8 商品兴趣度排行榜的综合计算\n",
    "import pandas as pd\n",
    "\n",
    "# 计算final_score\n",
    "user_features['final_score'] = user_features['tfidf_sum'] + user_features['time_penalty'] + user_features['payment_sum']\n",
    "\n",
    "# top10\n",
    "top10 = user_features.sort_values('final_score',ascending=False).head(10)\n",
    "\n",
    "print(top10[['time_penalty','payment_sum','tfidf_sum','final_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.9 交易次数可视化\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "text_list = '停彩|大乐透|双色球|福利彩票|彩票|竞彩|追号'\n",
    "\n",
    "# 选择排名前3的user_id\n",
    "top3 = top10.index.values[:3]\n",
    "\n",
    "# 不同ID的客户用不同的线段表示\n",
    "styles=['--','-',\":\"]\n",
    "\n",
    "fig = plt.figure(figsize=(15,6))\n",
    "\n",
    "# 绘制折线图\n",
    "for user_id,style in zip(top3,styles):\n",
    "     # 筛选用户的交易记录\n",
    "    top_select = consume.loc[consume['user_id'] == user_id]\n",
    "     # 匹配文本关键词\n",
    "    top_select = top_select[top_select['describe'].str.contains(text_list)]\n",
    "     # 按天分组，计算交易次数并绘图\n",
    "    top_select.groupby(top_select['pay_time'].dt.date).size().plot(style=style)\n",
    "\n",
    "# 设置标题\n",
    "plt.title('彩票交易次数变化')\n",
    "\n",
    "# 设置x,y轴标签\n",
    "plt.xlabel('日期')\n",
    "plt.ylabel('交易次数')\n",
    "# 设置图例\n",
    "plt.legend(labels=['第1名','第2名','第3名'])\n",
    "\n",
    "# 设置日期显示格式\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.10 交易金额的可视化\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "text_list = '停彩|大乐透|双色球|福利彩票|彩票|竞彩|追号'\n",
    "\n",
    "# 选择排名前3的user_id\n",
    "top3 = top10.index.values[:3]\n",
    "\n",
    "# 不同ID的客户用不同的线段表示\n",
    "styles = ['--','-',\":\"]\n",
    "\n",
    "fig = plt.figure(figsize=(15,6))\n",
    "\n",
    "for user_id,style in zip(top3,styles):\n",
    "    # 筛选用户的交易记录\n",
    "    top_select = consume.loc[consume['user_id'] == user_id]\n",
    "    # 匹配文本关键词\n",
    "    top_select = top_select[top_select['describe'].str.contains(text_list)]\n",
    "    # 按天分组，计算交易金额并绘图\n",
    "    top_select.groupby(top_select['pay_time'].dt.date)['payment'].sum().plot(style = style)\n",
    "\n",
    "# 设置标题\n",
    "plt.title('彩票交易金额变化')\n",
    "\n",
    "# 设置x,y轴标签\n",
    "plt.xlabel('日期')\n",
    "plt.ylabel('消费金额')\n",
    "\n",
    "# 设置图例\n",
    "plt.legend(labels = ['第1名','第2名','第3名'])\n",
    "\n",
    "# 设置日期显示格式\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.11 目标客户的筛选\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "\n",
    "# 构建连接对象\n",
    "connection = pymysql.connect(host='172.17.6.26', \n",
    "                             port=3306, \n",
    "                             user='raa_user', \n",
    "                             password='bigdata123', \n",
    "                             db='transactions',\n",
    "                             charset='utf8mb4',\n",
    "                             cursorclass=pymysql.cursors.DictCursor)\n",
    "\n",
    "try:\n",
    "    with connection.cursor() as cursor:\n",
    "        sql = \"SELECT * FROM user_features \\\n",
    "        WHERE business_travel_cnt > 0 AND credit_card_repay_cnt > 0 \\\n",
    "        AND is_installment= 1 AND sleep_customers = 0\\\n",
    "        ORDER BY credit_card_repay_cnt DESC LIMIT 200\"\n",
    "        cursor.execute(sql)\n",
    "        collected_users = cursor.fetchall()\n",
    "\n",
    "finally:\n",
    "    connection.close()\n",
    "\n",
    "# 查看筛选出的客户信息\n",
    "collected_users = pd.DataFrame(collected_users)\n",
    "print(collected_users[['user_id','business_travel_cnt','credit_card_repay_cnt']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
